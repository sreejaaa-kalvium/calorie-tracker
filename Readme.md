# ğŸ½ï¸ GenAI Calorie Tracker

## ğŸ“– Project Overview
The **GenAI Calorie Tracker** is an intelligent assistant that helps users monitor their daily food intake, estimate calories, and receive personalized diet suggestions.  
This project integrates **Generative AI (Gemini API)** with a backend calorie tracking system, enabling smart queries like:
- â€œHow many calories are in 2 bananas and a glass of milk?â€
- â€œSuggest a 2000-calorie vegetarian meal plan for today.â€
- â€œGive me a zero-carb dinner recipe.â€

The project also demonstrates advanced **prompt engineering techniques** like:
- Zero-Shot Prompting  
- Dynamic Prompting  
- Tokens & Tokenization Logging  
- Sampling Techniques (Temperature, Top-P, Top-K)

---

## ğŸ¯ Features
- ğŸ¥— **Food Logging** â€“ Track calories based on food inputs.  
- ğŸ§  **GenAI Bot** â€“ Query the model for summaries, recipes, or personalized diet advice.  
- ğŸ”‘ **Environment Config** â€“ API keys secured using `.env`.  
- ğŸ› ï¸ **Prompt Engineering** â€“ Zero-Shot, Dynamic Prompting, Temperature, Top-P, and Top-K implemented.  
- ğŸ“Š **Token Logging** â€“ Monitor tokens used in each request.  
- â˜ï¸ **Scalable Backend** â€“ Built to handle large requests and user traffic.  

---

## âš™ï¸ Tech Stack
- **Python 3.13+**
- **Google Gemini API** (`google-generativeai`)
- **dotenv** for environment variables
- **Git & GitHub** for version control
- **Prompt Engineering** concepts

---

## ğŸ—ï¸ Implementation

### 1. **Backend**
- The backend uses Python to connect with the Gemini API.
- API key is securely stored in `.env` file.

### 2. **Prompting**
- **Zero-Shot Prompting**: Directly ask the model without examples.  
- **Dynamic Prompting**: User input is dynamically included in the prompt.  
- **Temperature / Top-P / Top-K**: Adjust creativity and randomness in responses.  

### 3. **Token Management**
- After every AI call, token usage is logged in the console.  
- This helps measure **cost efficiency** and optimize prompts.  

### 4. **Scalability**
- The system is designed to handle multiple users.  
- By caching frequent queries and limiting token usage, the bot stays efficient even under heavy traffic.  


